---
title: "Tables with `dplyr`"
subtitle: "Modern Plain Text Social Science: Week 4"
format: kjhslides-revealjs
engine: knitr
filters: 
  - invert-h1
  - include-code-files
author:
  - name: Kieran Healy
    email: kieran.healy@duke.edu
date: last-modified
---




```{r}
#| label: "packages"
#| include: FALSE
library(flipbookr)
library(here)
library(tidyverse)
library(kjhslides)
```


```{r}
#| label: "setup"
#| include: FALSE

kjh_register_tenso()
kjh_set_knitr_opts()
kjh_set_slide_theme()
```

# [dplyr]{.fg-lblue} is your toolkit for tabular data 

---

:::{.huge}
 So let's<br />play with<br />some [data]{.fg-red} 
:::


::: aside
 woohoo! 
:::
 
## Load our libraries


```{r}
#| label: "03a-dplyr-basics-2"
#| message: TRUE
library(here)      # manage file paths
library(socviz)    # data and some useful functions
library(tidyverse) # your friend and mine
```


## Tidyverse components, again

:::: {.columns}
::: {.column width="55%"}
  - [**`library`**]{.fg-green}`(tidyverse)`
- `Loading tidyverse: ggplot2`
- `Loading tidyverse: tibble`
- `Loading tidyverse: tidyr`
- `Loading tidyverse: readr`
- `Loading tidyverse: purrr`
- `Loading tidyverse: dplyr`
:::

::: {.column width="45%" .left}
  - Call the package and ...
- `<|` **Draw graphs**
- `<|` **Nicer data tables**
- `<|` **Tidy your data**
- `<|` **Get data into R**
- `<|` **Fancy Iteration**
- `<|` **Action verbs for tables**
:::
::::


## Other tidyverse components

:::: {.columns}
::: {.column width="40%"}

- `forcats`
- `haven`
- `lubridate`
- `readxl`
- `stringr`
- `reprex`

:::

::: {.column width="60%" .left}

- `<|` **Deal with factors**
- `<|` **Import Stata, SPSS, etc**
- `<|` **Dates, Durations, Times**
- `<|` **Import from spreadsheets**
- `<|` **Strings and Regular Expressions**
- `<|` **Make reproducible examples**

:::
::::


::::: {.fragment fragment-index=1}
Not all of these are attached when we do `library(tidyverse)`    
:::::


## [dplyr]{.fg-yellow} lets you work with tibbles


::::: {.fragment fragment-index=1}
- Remember, tibbles are tables of data where the columns can be of different types, such as numeric, logical, character, factor, etc.
- We'll use dplyr to _transform_ and _summarize_ our data.
:::::

::::: {.fragment fragment-index=2}
- The core logic is: split, apply, combine:
- [Split]{.fg-lblue} or group the data into pieces
- [Apply]{.fg-orange} a function, i.e. act on the data in some way
- [Combine]{.fg-green} the results back into a table

::::: 

::::: {.fragment fragment-index=3}
- We'll use the pipe operator, [**`|>`**]{.fg-pink}, to chain together sequences of actions on our tables.
:::::


# dplyr's core verbs

---

:::{.huge}
 `dplyr` draws on the logic and language of  [database queries]{.fg-green} 
:::

---


## Some [actions]{.fg-orange} to take on a single table 

::: {.incremental}
- [**Subset**]{.fg-orange} either the rows or columns of or table—i.e. remove them before doing anything.

- [**Group**]{.fg-orange} the data at the level we want, such as "By Race", or "By Country", or “_By Religion within Regions_” or “_By Grade within Schools_”.

- [**Mutate**]{.fg-orange} the data. That is, change something at the _current_ level of grouping.  Mutating adds new columns to the table, or changes the content of an existing column. It never changes the number of rows.

- [**Summarize**]{.fg-orange} or aggregate the data. That is, make something new at a _higher_ level of grouping. E.g., calculate means or counts by some grouping variable. This will generally result in a smaller, _summary_ table. Usually this will have the same number of _rows_ as there are _groups_ being summarized.
:::


## For each [action]{.fg-orange} there's a [function]{.fg-green} 

::: {.incremental}
- [**Subset**]{.fg-orange} has one function for rows and one for columns. We **`filter()`** rows and **`select()`** columns.
- [**Group**]{.fg-orange} using  **`group_by()`**.
- [**Mutate**]{.fg-orange} tables (i.e. add new columns, or re-make existing ones) using **`mutate()`**.
- [**Summarize**]{.fg-orange} tables (i.e. perform aggregating calculations) using **`summarize()`**.
:::

# Group and Summarize

## General Social Survey data: [`gss_sm`]{.fg-pink}

```{r }
#| label: "03a-dplyr-basics-3"
## library(socviz) # if not loaded
gss_sm
```

::::: {.fragment fragment-index=1}
Notice how the tibble already tells us a lot.    
:::::

## Summarizing a Table

- Here's what we're going to do:

![](../assets/04-r/04_dplyr-pipe-example.png)]

## Summarizing a Table

```{r }
#| label: "03a-dplyr-basics-4"
gss_sm |> 
  select(id, bigregion, religion)
```

We're just taking a look at the relevant columns here.

## Group by [_one_]{.fg-orange} column or variable

```{r }
#| label: "03a-dplyr-basics-5"

gss_sm |> 
  group_by(bigregion)
```

Grouping just changes the logical structure of the tibble. 

---

`r chunq_reveal("03a-dplyr-basics-6", smallcode = TRUE, title = "Group and summarize by _one_ column")`


```{r}
#| label: "03a-dplyr-basics-6"
#| include: FALSE
gss_sm |> 
  group_by(bigregion) |> 
  summarize(total = n())
```

::: {.incremental}
- The function [**`n()`**]{.fg-green} counts up the rows within each group.    
- All the other columns are dropped in the summary operation
- Your original [`gss_sm`]{.fg-pink} table is untouched
:::


---

`r chunq_reveal("03a-dplyr-basics-7", smallcode = TRUE, title = "Group and summarize by _two_ columns")`


```{r}
#| label: "03a-dplyr-basics-7"
#| include: FALSE
gss_sm |> 
  group_by(bigregion, religion) |> 
  summarize(total = n())
```

::: {.incremental}
- The function [**`n()`**]{.fg-green} counts up the rows within the _innermost_ (i.e. the rightmost) group.
:::


---

`r chunq_reveal("03a-dplyr-basics-8", smallcode = TRUE, title = "Calculate frequencies")`

```{r}
#| label: "03a-dplyr-basics-8"
#| include: FALSE
gss_sm |> 
  group_by(bigregion, religion) |> 
  summarize(total = n()) |> 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1))
```


::: {.incremental}
- The function [**`n()`**]{.fg-green} counts up the rows 
- Which rows? The ones fed down the pipeline
- The _innermost_ (i.e. the rightmost) group.
:::

## Pipelines carry assumptions forward

```{r }
#| label: "03a-dplyr-basics-9"
gss_sm |> 
  group_by(bigregion, religion) |> #<<
  summarize(total = n()) |> 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1))
```

:::{.tiny}
Groups are carried forward till summarized or explicitly ungrouped

Summary calculations are done on the innermost group, which then "disappears". (It becomes the rows in the summary table.)
:::


## Pipelines carry assumptions forward

```{r }
#| label: "03a-dplyr-basics-10"
gss_sm |> 
  group_by(bigregion, religion) |> 
  summarize(total = n()) |> 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1)) #<<
```


[**`mutate()`**]{.fg-green} is quite clever. See how we can immediately use **`freq`**, even though we are creating it in the same [**`mutate()`**]{.fg-green} expression.


## Convenience functions

```{r }
#| label: "03a-dplyr-basics-11"
gss_sm |> 
  group_by(bigregion, religion) |> #<<
  summarize(total = n()) |> #<<
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1)) 
```

We're going to be doing this [**`group_by()`**]{.fg-green} ... [**`n()`**]{.fg-green} step a lot. Some shorthand for it would be useful.

## Three options for counting up rows 

:::: {.columns}
::: {.column width="30%"}
  -  Use [**`n()`**]{.fg-green}

::::: {.smallcode}
```{r }
#| label: "03a-dplyr-basics-12"
gss_sm |> 
  group_by(bigregion, religion) |> #<<
  summarize(n = n()) #<<
```
:::::

- Group it yourself; result is grouped.
:::
  
::: {.column width="30%"}
- Use [**`tally()`**]{.fg-green}

::::: {.smallcode}
```{r }
#| label: "03a-dplyr-basics-13"
gss_sm |> 
  group_by(bigregion, religion) |> 
  tally() #<<
```
:::::
- More compact; result is grouped.

:::

::: {.column width="30%" .right}
 - Use [**`count()`**]{.fg-green}

::::: {.smallcode}
```{r }
#| label: "03a-dplyr-basics-14"
gss_sm |> 
  count(bigregion, religion) #<<
```
:::::
- One step; result is not grouped.

:::
::::

## Pass results on to ... a [table]{.fg-yellow}

```{r}
#| label: "03a-dplyr-basics-15"
#| eval: FALSE
gss_sm |> 
  count(bigregion, religion) |> 
  pivot_wider(names_from = bigregion, values_from = n) |>  #<<
  tinytable::tt()  
```

```{r}
#| label: "03a-dplyr-basics-16"
#| echo: FALSE
gss_sm |> 
  count(bigregion, religion) |> 
  pivot_wider(names_from = bigregion, values_from = n) |> 
  tinytable::tt()  
```


- More on [**`pivot_wider()`**]{.fg-green} soon ...



## Pass results on to ... a [graph]{.fg-yellow}

```{r}
#| label: "03a-dplyr-basics-17"
#| fig.height: 4
#| fig.width: 15
gss_sm |> 
  group_by(bigregion, religion) |> 
  tally() |> 
  mutate(pct = round((n/sum(n))*100), 1) |> 
  drop_na() |> 
  ggplot(mapping = aes(x = pct, y = reorder(religion, -pct), fill = religion)) + #<<
  geom_col() + #<<
    labs(x = "Percent", y = NULL) +
    guides(fill = "none") + 
    facet_wrap(~ bigregion, nrow = 1)
```

## Pass results on to ... an [object]{.fg-yellow}

:::: {.columns}
::: {.column width="50%"}
  - You can do it like this ...
```{r }
#| label: "03a-dplyr-basics-18"
rel_by_region <- gss_sm |> #<<
  count(bigregion, religion) |> 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```

:::

::: {.column width="50%" .right}
:::
::::


## Pass results on to ... an [object]{.fg-yellow}

:::: {.columns}
::: {.column width="50%"}
  - You can do it like this ...
```{r }
#| label: "03a-dplyr-basics-18b"
rel_by_region <- gss_sm |> #<<
  count(bigregion, religion) |> 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```

:::

::: {.column width="50%" .right}
-  Or like this!
```{r }
#| label: "03a-dplyr-basics-19"
gss_sm |> 
  count(bigregion, religion) |> 
  mutate(pct = round((n/sum(n))*100, 1)) -> #<<
rel_by_region #<<

rel_by_region
```

:::
::::


## [Right]{.fg-lblue} assignmment is a thing, like [Left]{.fg-red}

:::: {.columns}
::: {.column width="50%"}
- [Left]{.fg-red} assignment is standard

```{r }
#| label: "03a-dplyr-basics-20"
gss_tab <- gss_sm |> 
  count(bigregion, religion) 
```

- This may feel awkward with a pipe: "`gss_tab` [_gets_]{.fg-orange} the output of the following pipeline."

:::

::: {.column width="50%" .right}
- [Right]{.fg-lblue} assignment also works!

```{r }
#| label: "03a-dplyr-basics-21"
gss_sm |> 
  count(bigregion, religion) -> gss_tab  
  
```

- Without any authority, I assert that right-assignment should be read as, e.g., "This pipeline [_begets_]{.fg-orange} `gss_tab`"

:::
::::


## Check by summarizing

:::: {.columns}
::: {.column width="50%"}

```{r }
#| label: "03a-dplyr-basics-22"
rel_by_region <- gss_sm |> 
  count(bigregion, religion) |> 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```

Hm, did I sum over right group?

:::

::: {.column width="50%" .right}

:::
::::


## Check by summarizing

:::: {.columns}
::: {.column width="50%"}

```{r }
#| label: "03a-dplyr-basics-22b"
rel_by_region <- gss_sm |> 
  count(bigregion, religion) |> 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```

Hm, did I sum over right group?

:::

::: {.column width="50%" .right}
```{r }
#| label: "03a-dplyr-basics-23"
## Each region should sum to ~100
rel_by_region |> 
  group_by(bigregion) |> 
  summarize(total = sum(pct)) 

```

No! What has gone wrong here?

:::
::::



## Check by summarizing

:::: {.columns}
::: {.column width="50%"}

```{r }
#| label: "03a-dplyr-basics-24b"
rel_by_region <- gss_sm |> 
  count(bigregion, religion) |> #<<
  mutate(pct = round((n/sum(n))*100, 1)) 
```

::::: {.tiny}
[**`count()`**]{.fg-green} returns ungrouped results, so there are no groups carry forward to the [**`mutate()`**]{.fg-green} step.
:::::

```{r }
#| label: "03a-dplyr-basics-25"
rel_by_region |> 
  summarize(total = sum(pct))
```

::::: {.tiny}
With [**`count()`**]{.fg-green}, the `pct` values here are the marginals for the whole table.
:::::

:::

::: {.column width="50%" .right}

:::
::::


## Check by summarizing

:::: {.columns}
::: {.column width="50%"}

```{r }
#| label: "03a-dplyr-basics-24"
rel_by_region <- gss_sm |> 
  count(bigregion, religion) |> #<<
  mutate(pct = round((n/sum(n))*100, 1)) 
```

::::: {.tiny}
[**`count()`**]{.fg-green} returns ungrouped results, so there are no groups carry forward to the [**`mutate()`**]{.fg-green} step.
:::::


```{r }
#| label: "03a-dplyr-basics-25b"
rel_by_region |> 
  summarize(total = sum(pct))
```

::::: {.tiny}
With [**`count()`**]{.fg-green}, the `pct` values here are the marginals for the whole table.
:::::
:::

::: {.column width="50%" .right}
```{r }
#| label: "03a-dplyr-basics-26"
rel_by_region <- gss_sm |> 
  group_by(bigregion, religion) |> #<<
  tally() |> #<<
  mutate(pct = round((n/sum(n))*100, 1)) 
```

```{r }
#| label: "03a-dplyr-basics-27"
# Check
rel_by_region |> 
  group_by(bigregion) |> 
  summarize(total = sum(pct))

```

::::: {.tiny}
We get some rounding error because we used `round()` after summing originally.
:::::

:::
::::


## Two lessons

### Check your tables!

::: {.incremental}
- Pipelines feed their content forward, so you need to make sure your results are not incorrect.
- Often, complex tables and graphs can be disturbingly plausible even when wrong.
- So, figure out what the result should be and test it!
- Starting with simple or toy cases can help with this process.

:::


## Two lessons

### Inspect your pipes!

::: {.incremental}
- Understand pipelines by running them forward or peeling them back a step at a time.
- This is a _very_ effective way to understand your own and other people's code.
:::

# Another example

## Following a pipeline

```{r}
#| label: "03a-dplyr-basics-28"
#| echo: FALSE
#theme_set(cowplot::theme_minimal_grid())
```


```{r }
#| label: "03a-dplyr-basics-29"
#| fig.height: 4
#| fig.width: 10
gss_sm |> 
  group_by(race, sex, degree) |> 
  summarize(n = n(), 
            mean_age = mean(age, na.rm = TRUE), 
            mean_kids = mean(childs, na.rm = TRUE)) |> 
  mutate(pct = n/sum(n)*100) |> 
  filter(race !="Other") |> 
  drop_na() |> 
  ggplot(mapping = aes(x = mean_kids, y = degree)) + # Some ggplot ...
  geom_col() + facet_grid(sex ~ race) + 
  labs(x = "Average number of Children", y = NULL)
```

`r chunq_reveal("03a-dplyr-basics-30", smallcode = TRUE,  lcolw = "38", rcolw = "62", title = "Following a pipeline")`


```{r }
#| label: "03a-dplyr-basics-30"
#| include: FALSE
gss_sm |> 
  group_by(race, sex, degree) |> 
  summarize(n = n(), 
    mean_age = mean(age, na.rm = TRUE), 
    mean_kids = mean(childs, na.rm = TRUE)) |> 
  mutate(pct = n/sum(n)*100) |> 
  filter(race !="Other") |> 
  drop_na() |> 
  summarize(grp_totpct = sum(pct))
```


# Conditional selection

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

- Some new data, this time on national rates of cadaveric organ donation:

```{r }
#| label: "03a-dplyr-basics-31"
# library(socviz)
organdata
```


## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-32"
organdata |> 
  filter(consent_law == "Informed" & donors > 15) 
```

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-33"
organdata |> 
  select(country, year, where(is.integer)) #<<
```

Use [**`where()`**]{.fg-green} to test columns.

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

When telling [**`where()`**]{.fg-green} to use [**`is.integer()`**]{.fg-green} to test each column, we don't put parentheses at the end of its name. If we did, R would try to evaluate [**`is.integer()`**]{.fg-green} right then, and fail:

```r
> organdata |> 
+   select(country, year, where(is.integer()))
Error: 0 arguments passed to 'is.integer' which requires 1
Run `rlang::last_error()` to see where the error occurred.
```

This is true in similar situations elsewhere as well.

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-34"
organdata |> 
  select(country, year, where(is.character))
```

We have functions like e.g. [**`is.character()`**]{.fg-green}, [**`is.numeric()`**]{.fg-green}, [**`is.logical()`**]{.fg-green}, [**`is.factor()`**]{.fg-green}, etc. All return either [`TRUE`]{.fg-green} or [`FALSE`]{.fg-red}. 

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

Sometimes we don't pass a function, but do want to use the result of one:

```{r }
#| label: "03a-dplyr-basics-35"
organdata |> 
  select(country, year, starts_with("gdp")) #<<
```

::: {.tiny}
We have [**`starts_with()`**]{.fg-green}, [**`ends_with()`**]{.fg-green}, [**`contains()`**]{.fg-green}, [**`matches()`**]{.fg-green}, and [**`num_range()`**]{.fg-green}. Collectively these are "[tidy selectors]{.fg-pink}".
:::

## Conditionals in [`select()`]{.fg-green} & [`filter()`]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-36"
organdata |> 
  filter(country == "Australia" | country == "Canada") 
```

This could get cumbersome fast.

## Use [`%in%`]{.fg-pink} for multiple selections

```{r }
#| label: "03a-dplyr-basics-37"
my_countries <- c("Australia", "Canada", "United States", "Ireland")

organdata |> 
  filter(country %in% my_countries) #<<
```

## Negating [`%in%`]{.fg-pink} 

```{r }
#| label: "03a-dplyr-basics-38"
my_countries <- c("Australia", "Canada", "United States", "Ireland")

organdata |> 
  filter(!(country %in% my_countries)) #<<
```

Also a bit awkward. There's no built-in "Not in" operator. 

## A custom operator 

```{r }
#| label: "03a-dplyr-basics-39"
`%nin%` <- Negate(`%in%`) # this operator is included in the socviz package
```

::: aside
The backticks are special here because we need to name an operator. 
:::

```{r }
#| label: "03a-dplyr-basics-40"
organdata |> 
  filter(country %nin% my_countries) #<<
```

# Using `across()`

## Do more than one thing 

Earlier we saw this:

```{r }
#| label: "03a-dplyr-basics-41"
gss_sm |> 
  group_by(race, sex, degree) |> 
  summarize(n = n(), 
            mean_age = mean(age, na.rm = TRUE), 
            mean_kids = mean(childs, na.rm = TRUE))
```

## Do more than one thing 

Similarly for `organdata` we might want to do:

```{r }
#| label: "03a-dplyr-basics-42"
organdata |>  
  group_by(consent_law, country) |>
  summarize(donors_mean = mean(donors, na.rm = TRUE),
            donors_sd = sd(donors, na.rm = TRUE),
            gdp_mean = mean(gdp, na.rm = TRUE),
            health_mean = mean(health, na.rm = TRUE),
            roads_mean = mean(roads, na.rm = TRUE))
```


This works, but it's really tedious. Also error-prone.

## Use [**`across()`**]{.fg-green} 

Instead, use [`across()`]{.fg-green} to apply a function to more than one column.

```{r }
#| label: "03a-dplyr-basics-43"

my_vars <- c("gdp", "donors", "roads")

## nested parens again, but it's worth it
organdata |> 
  group_by(consent_law, country) |>
  summarize(across(all_of(my_vars),           
                   list(avg = \(x) mean(x, na.rm = TRUE))
                  )
           )     
```

`r chunq_reveal("03a-dplyr-basics-43", smallcode = TRUE, widths = c(40,60), title = "Let's look at that again")`


## Let's look at that again

```{r}
#| eval: false

my_vars <- c("gdp", "donors", "roads")

organdata |> 
  group_by(consent_law, country) |>
  summarize(across(all_of(my_vars),           
                   list(avg = \(x) mean(x, na.rm = TRUE))
                  )
           )     
```

::: {.incremental}

- `my_vars` are selected by [**`across()`**]{.fg-green}
- We use `all_of()` or `any_of()` to be explicit
- [**`list()`**]{.fg-green} of the form `result = function` gives the new columns that will be calculated.
- The thing inside the list with the "waving person", `\(x)`, is an _anonymous function_ 

:::



## We can calculate more than one thing

```{r }
#| label: "03a-dplyr-basics-44"

my_vars <- c("gdp", "donors", "roads")

organdata |> 
  group_by(consent_law, country) |>
  summarize(across(all_of(my_vars),           
                   list(avg = \(x) mean(x, na.rm = TRUE), #<<
                        sdev = \(x) sd(x, na.rm = TRUE), #<<
                        md = \(x) median(x, na.rm = TRUE)) #<<
                  )
           )
```

## It's OK to use the function names 

```{r }
#| label: "03a-dplyr-basics-45"

my_vars <- c("gdp", "donors", "roads")

organdata |> 
  group_by(consent_law, country) |>
  summarize(across(all_of(my_vars),           
                   list(mean = \(x) mean(x, na.rm = TRUE), #<<
                        sd = \(x) sd(x, na.rm = TRUE), #<<
                        median = \(x) median(x, na.rm = TRUE)) #<<
                  )
           )
```

## Selection with [**`across(where())`**]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-46"

organdata |> 
  group_by(consent_law, country) |>
  summarize(across(where(is.numeric),           
                   list(mean = \(x) mean(x, na.rm = TRUE), #<<
                        sd = \(x) sd(x, na.rm = TRUE), #<<
                        median = \(x) median(x, na.rm = TRUE)) #<<
                  )
           ) |> 
    print(n = 3) # just to save slide space
```


## Name new columns with [**`.names`**]{.fg-green}

```{r }
#| label: "03a-dplyr-basics-47"
organdata |> 
  group_by(consent_law, country) |>
  summarize(across(where(is.numeric),           
                   list(mean = \(x) mean(x, na.rm = TRUE), #<<
                        sd = \(x) sd(x, na.rm = TRUE), #<<
                        median = \(x) median(x, na.rm = TRUE)) #<<
                  ),
            .names = "{fn}_{col}") |> #<<
  print(n = 3) 
```


## Name new columns with [**`.names`**]{.fg-green}

In tidyverse functions, arguments that begin with a "`.`" generally have it in order to avoid confusion with existing items, or are "pronouns" referring to e.g. "the name of the thing we're currently talking about as we evaluate this function". 

  

## This all works with [**`mutate()`**]{.fg-green}, too


```{r }
#| label: "03a-dplyr-basics-48"
organdata |> 
  mutate(across(where(is.character), toupper)) |> 
  select(where(is.character))
```

## Arrange rows and columns

Sort rows with [**`arrange()`**]{.fg-green}

:::: {.columns}
::: {.column width="50%"}
```{r }
#| label: "03a-dplyr-basics-49"
organdata |> 
  group_by(consent_law, country) |>
  summarize(donors = mean(donors, na.rm = TRUE)) |> 
  arrange(donors) |> ##<
  print(n = 5)
```

:::

::: {.column width="50%" .right}

:::
::::

## Arrange rows and columns

Sort rows with [**`arrange()`**]{.fg-green}

:::: {.columns}
::: {.column width="50%"}
```{r }
#| label: "03a-dplyr-basics-49b"
organdata |> 
  group_by(consent_law, country) |>
  summarize(donors = mean(donors, na.rm = TRUE)) |> 
  arrange(donors) |> ##<
  print(n = 5)
```

:::

::: {.column width="50%" .right}
```{r }
#| label: "03a-dplyr-basics-50"
organdata |> 
  group_by(consent_law, country) |>
  summarize(donors = mean(donors, na.rm = TRUE)) |> 
  arrange(desc(donors)) |>  ##<
  print(n = 5)
```

Using [**`arrange()`**]{.fg-green} to order rows in this way won't respect groupings.

:::
::::


## More generally ...

```{r }
#| label: "03a-dplyr-basics-51"
organdata |> 
  group_by(consent_law, country) |>
  summarize(donors = mean(donors, na.rm = TRUE)) |> 
  slice_max(donors, n = 5) #<<
```

- You can see that [**`slice_max()`**]{.fg-green} respects grouping.
- There's [**`slice_min()`**]{.fg-green}, [**`slice_head()`**]{.fg-green}, [**`slice_tail()`**]{.fg-green}, [**`slice_sample()`**]{.fg-green}, and the most general one, [**`slice()`**.]{.fg-green}



## **`dplyr`**'s [window]{.fg-yellow} functions 

Ranking and cumulation within groups.  


```{r }
#| label: "03b-dplyr-basics-3"
## Data on COVID-19
library(covdata)

covnat_weekly 
```

## **`dplyr`**'s [window]{.fg-yellow} functions 

[**`cumsum()`**]{.fg-green} gives cumulative sums

```{r }
#| label: "03b-dplyr-basics-4"
covnat_weekly |> 
  filter(iso3 == "FRA") |> 
  select(date, cname, iso3, cases) |> 
  mutate(cases = ifelse(is.na(cases), 0, cases), # convert NA vals in `cases` to 0
         cumulative = cumsum(cases)) 

```

## **`dplyr`**'s [window]{.fg-yellow} functions 

[**`cume_dist()`**]{.fg-green} gives the proportion of values <= to the current value.

```{r }
#| label: "03b-dplyr-basics-5"
covnat_weekly |> 
  select(date, cname, iso3, deaths) |> 
  filter(iso3 == "FRA") |> 
  filter(cume_dist(desc(deaths)) < 0.1) # i.e. Top 10%

```

::: aside
The `dplyr` vignette on Window functions is good.  
:::

## An application 

```{r }
#| label: "03b-dplyr-basics-6"
covus |> 
  filter(measure == "death") |> 
  group_by(state) |> 
  arrange(state, desc(date)) |> 
  filter(state %in% "NY")
```

Here the `count` measure is _cumulative_ deaths. What if we want to recover the daily count for all the states in the data?

## An application 

`dplyr` has [**`lead()`**]{.fg-green} and [**`lag()`**]{.fg-green} functions. These allow you to access the previous and next values in a vector. You can calculate offsets this way.

```{r }
#| label: "03b-dplyr-basics-7"
my_vec <- c(1:20)
my_vec
lag(my_vec) # first element has no lag

my_vec - lag(my_vec)

```

## An application

We can write the expression directly:

```{r }
#| label: "03b-dplyr-basics-8"
covus |>
  select(-data_quality_grade) |> 
  filter(measure == "death") |>
  group_by(state) |>
  arrange(date) |> 
  mutate(deaths_daily = count - lag(count, order_by = date)) |> 
  arrange(state, desc(date)) |> 
  filter(state %in% "NY")
  
```


## Writing our own [functions]{.fg-orange}

We write functions using the special [**`function()`**]{.fg-green} function.\*


```{r }
#| label: "03b-dplyr-basics-9"
my_fun <- function(x) {
  x + 1
}

my_fun # we've created the function; it's just an object

my_fun(x = 1) # But we can supply it with an input!

my_fun(10)
```


::: aside
\*Nerds love this sort of stuff.  
:::

## Writing our own [functions]{.fg-orange}

We write our function. It's just the expression we originally wrote, wrapped up.

```{r }
#| label: "03b-dplyr-basics-10"
get_daily_count <- function(count, date){
  count - lag(count, order_by = date)
}
```

This function has no generality, error-handling, or anything else. It's a once-off.

## Writing our own [functions]{.fg-orange}

Now we can use it like any other:

```{r }
#| label: "03b-dplyr-basics-11"
covus |>
  filter(measure == "death") |>
  select(-data_quality_grade) |> 
  group_by(state) |>
  arrange(date) |> 
  mutate(deaths_daily = get_daily_count(count, date)) |> 
  arrange(state, desc(date)) |> 
  filter(state %in% "NY")
  
```


Not super-useful quite yet, but if our task had more steps ...

# The [`slider`]{.fg-orange} package

## Tidy moving averages with [`slider`]{.fg-orange}  

**`dplyr`**'s window functions don't include moving averages. 

There are several options, notably [`RcppRoll`](https://cran.r-project.org/web/packages/RcppRoll/index.html)

We'll use the [`slider`](https://cran.r-project.org/web/packages/slider/vignettes/slider.html) package.

```{r }
#| label: "03b-dplyr-basics-12"
# install.packages("slider")
library(slider)
```

## Tidy moving averages with [`slider`]{.fg-orange}  

```{r }
#| label: "03b-dplyr-basics-13"
covus |>
  filter(measure == "death") |>
  select(-data_quality_grade) |> 
  group_by(state) |>
  arrange(date) |> 
  mutate(
    deaths_daily = get_daily_count(count, date), 
    deaths7 = slide_mean(deaths_daily, #<<
                         before = 7, #<<
                         na_rm = TRUE)) |> #<<
  arrange(state, desc(date)) |> 
  filter(state %in% "NY")
```


## Tidy moving averages with [`slider`]{.fg-orange}  

```r
    deaths7 = slide_mean(deaths_daily, 
                         before = 7, 
                         na_rm = TRUE)) |> 
```

Notice the Tidyverse-style `na_rm` argument rather than the usual base `na.rm`

The package provides a lot of different functions, from general-purpose [**`slide_max()`**]{.fg-green}, [**`slide_min()`**]{.fg-green} to more specialized sliding functions. In particular note e.g. [**`slide_index_mean()`**]{.fg-green} that addresses some subtleties in averaging over dates with gaps. 


## Move columns with [**`relocate()`**]{.fg-green}

```{r }
#| label: "03b-dplyr-basics-14"
gss_sm
```

```{r}
#| label: "03b-dplyr-basics-15"
#| include: FALSE
gss_sm |> 
  select(region, bigregion, year, 
         id:region, 
         starts_with("p"), 
         contains("income")) |> 
  rename(children = childs, 
         siblings = sibs) |> 
  relocate(id) |> 
  select(-ballot) |> 
  relocate(where(is.numeric), 
           .before = where(is.factor)) |> 
  relocate(contains("region"), 
           .after = year) 
```

`r chunq_reveal("03b-dplyr-basics-15", smallcode = TRUE, lcolw="35", rcolw="65", title = "Shuffle columns around")`

## Example: UK Election Data

```{r }
#| label: "03b-dplyr-basics-16"
library(ukelection2019)

ukvote2019
```

## Example: UK Election Data

Use [**`sample_n()`**]{.fg-green} to sample `n` rows of your tibble.

```{r }
#| label: "03b-dplyr-basics-17"
library(ukelection2019)

ukvote2019 |> 
  sample_n(10)
```

## Example: UK Election Data

- A vector of unique constituency names

```{r}
#| label: "03b-dplyr-basics-18"
ukvote2019 |> 
  distinct(constituency)
```


## Example: UK Election Data

- Tally them up

```{r}
#| label: "03b-dplyr-basics-19"
ukvote2019 |> 
  distinct(constituency) |> 
  tally()
```

```{r}
#| label: "03b-dplyr-basics-20"
# Base R / non-pipeline version

length(unique(ukvote2019$constituency))
```


## Example: UK Election Data

Which parties fielded the most candidates?

```{r}
#| label: "03b-dplyr-basics-21"
ukvote2019 |> 
  count(party_name) |> 
  arrange(desc(n))
```

## Example: UK Election Data

:::: {.columns}
::: {.column width="50%"}
- Top 5
```{r}
#| label: "03b-dplyr-basics-22"
ukvote2019 |> 
  count(party_name) |> 
  slice_max(order_by = n, n = 5)

```

:::

::: {.column width="50%" .right}

:::
::::

## Example: UK Election Data

:::: {.columns}
::: {.column width="50%"}
- Top 5
```{r}
#| label: "03b-dplyr-basics-22a"
ukvote2019 |> 
  count(party_name) |> 
  slice_max(order_by = n, n = 5)

```

:::

::: {.column width="50%" .right}
- Bottom 5
```{r}
#| label: "03b-dplyr-basics-23"
ukvote2019 |> 
  count(party_name) |> 
  slice_min(order_by = n, n = 5)

```
:::
::::


## Example: UK Election Data

How many constituencies are there?

:::: {.columns}
::: {.column width="50%"}
```{r}
#| label: "03b-dplyr-basics-24"
ukvote2019 |> 
  count(constituency) 
```
:::

::: {.column width="50%" .right}
```{r}
ukvote2019 |> 
  distinct(constituency) |> 
  count()
```

```{r}
# Base R style ...
length(unique(ukvote2019$constituency))
```

:::
::::

## Counting Twice Over

```{r}
#| label: "03b-dplyr-basics-25"
ukvote2019 |> 
  count(constituency) |> 
  count(n)
```

```{r}
#| label: "03b-dplyr-basics-26"
#| include: FALSE

ukvote2019 |> 
  count(constituency, name = "n_cands") |> 
  count(n_cands, name = "n_const")
```

`r chunq_reveal("03b-dplyr-basics-26", smallcode = TRUE, lcolw = "45", rcolw = "55", title = "Counting Twice Over")`

# Recap and Looking Ahead

## Recap and Looking Ahead

###  Coding as gardening

### Working in RStudio with RMarkdown documents


## Core [`dplyr`]{.fg-orange} verbs

- Subset your table: [`filter()`]{.fg-green} rows, [`select()`]{.fg-green} columns
- Logically [`group_by()`]{.fg-green} one or more columns
- Add columns with [`mutate()`]{.fg-green}
- Summarize (by group, or the whole table) with [`summarize()`]{.fg-green}

## Expand your [`dplyr`]{.fg-orange} actions

- Count up rows with [`n()`]{.fg-green}, [`tally()`]{.fg-green} or [`count()`]{.fg-green}
- Calculate quantities with [`sum()`]{.fg-green}, [`mean()`]{.fg-green}, [`min()`]{.fg-green}, etc
- Subset rows with logical expressions or [`slice`]{.fg-green} functions
- Conditionally select columns by name directly, with [`%in%`]{.fg-green} or [`%nin%`]{.fg-green}, or with tidy selectors like [`starts_with()`]{.fg-green}, [`ends_with()`]{.fg-green}, [`contains()`]{.fg-green}
- Conditionally select columns by _type_ with [`where()`]{.fg-green} and some criterion, e.g. [`where(is.numeric)`]{.fg-green}
- Conditionally select and then _act_ on columns with [`across(where(`]{.fg-green}[`<condition>`]{.fg-orange}[`),`]{.fg-green} [`<action>`]{.fg-orange}[`)`]{.fg-green}


## Expand your [`dplyr`]{.fg-orange} actions

- Tidy up columns with [`relocate()`]{.fg-green} and [`rename()`]{.fg-green}
- Tidy up rows with [`arrange()`]{.fg-green}

# A dplyr shortcut

## A dplyr shortcut

So far we have been writing, e.g.,

```{r}
#| label: "03b-dplyr-basics-by-1"
gss_sm |> 
  group_by(bigregion, religion) |> 
  summarize(total = n())
```


## A dplyr shortcut

Or

```{r}
#| label: "03b-dplyr-basics-by-2"
gss_sm |> 
  group_by(bigregion, religion) |> 
  tally()
```

## A dplyr shortcut

Or

```{r}
#| label: "03b-dplyr-basics-by-3"
gss_sm |> 
  count(bigregion, religion) 
```

With this last one the final result is _ungrouped_, no matter how many levels of grouping there are going in.

## A dplyr shortcut

But we can also write this:

```{r}
#| label: "03b-dplyr-basics-by-4"
gss_sm |> 
  summarize(total = n(), .by = c(bigregion, religion))
```

::: {.tiny}
By default the result is an _ungrouped_ tibble, whereas with `group_by()` ... `summarize()` the result would still be grouped by `bigregion` at the end. To prevent unexpected results, you can't use `.by` on tibble that's already grouped.
:::

## Data as implicitly first

This code:

```{r}
#| label: "03b-dplyr-basics-by-5"
gss_sm |> 
  summarize(total = n(), .by = c(bigregion, religion))
```



## Data as implicitly first

... is equivalent to this:

```{r}
#| label: "03b-dplyr-basics-by-6"
summarize(gss_sm, total = n(), .by = c(bigregion, religion))
```

This is true of Tidyverse pipelines in general. Let's look at the help for `summarize()` to see why. 

# Two dplyr [gotchas]{.fg-red}

## Comparisons filtering on proportions

Let's say you are working with proportions ... 

```{r}
#| label: "03b-dplyr-basics-27"
#| echo: FALSE

# Make some sample data with tribb
df <- tribble(~id, ~ prop1, ~prop2,
              "A", 0.1,      0.2,
              "B", 0.1,      0.21, 
              "C", 0.11,     0.2,
              "D", 0.1,      0.1)
```

```{r}
#| label: "03b-dplyr-basics-28"
df
```

## Comparisons filtering on proportions

And you want to focus on cases where `prop1` _plus_ `prop2` is greater than 0.3:

```{r}
#| label: "03b-dplyr-basics-29"
df |> 
  filter(prop1 + prop2 > 0.3)
```

::::: {.fragment fragment-index=1}
- The row with `id` [**`A`**]{.fg-orange} shouldn't have been included there.    
- This is not dplyr's fault. It's our floating point friend again.
:::::

## Comparisons filtering on proportions

```{r}
#| label: "03b-dplyr-basics-30"
df |> 
  filter(prop1 + prop2 == 0.3)
```

The row with `id` [**`A`**]{.fg-orange} _should_ have been included here!

## Comparisons filtering on proportions

This won't give the right behavior either:

```{r}
#| label: "03b-dplyr-basics-31"
df |> 
  mutate(prop3 = prop1 + prop2) |> 
  filter(prop3 == 0.3)
```

## Comparisons filtering on proportions

So, beware.

```{r}
#| label: "03b-dplyr-basics-32"
df |> 
  filter(prop1*100 + prop2*100 == 0.3*100)
```

Better:

```{r}
#| label: "03b-dplyr-basics-33"
df |> 
  filter(near(prop1 + prop2, 0.3))
```


## [Zero Counts]{.fg-orange} in dplyr

```{r}
#| label: "03b-dplyr-basics-34"
df <- read_csv(here("files", "examples", "first_terms.csv"))

df
```

## [Zero Counts]{.fg-orange} in dplyr

```{r}
#| label: "03b-dplyr-basics-35"
#| echo: FALSE
## Hex colors for sex
sex_colors <- c("#E69F00", "#993300")

## Group labels
mf_labs <- tibble(M = "Men", F = "Women")

```


```{r}
#| label: "03b-dplyr-basics-36"
df |>
    group_by(start_year, party, sex) |>
    summarize(N = n()) |>
    mutate(freq = N / sum(N))

```

## [Zero Counts]{.fg-orange} in dplyr


```{r}
#| label: "03b-dplyr-basics-37"
p_col <- df |>
    group_by(start_year, party, sex) |>
    summarize(N = n()) |>
    mutate(freq = N / sum(N)) |>
    ggplot(aes(x = start_year,
               y = freq,
               fill = sex)) +
    geom_col() +
    scale_y_continuous(labels = scales::percent) +
    scale_fill_manual(values = sex_colors, labels = c("Women", "Men")) +
    labs(x = "Year", y = "Percent", fill = "Group") +
    facet_wrap(~ party)
```

## [Zero Counts]{.fg-orange} in dplyr

```{r}
#| label: "03b-dplyr-basics-38"
#| fig.height: 6
#| fig.width: 10
p_col
```

## 2.  [Zero Counts]{.fg-orange} in dplyr

```{r}
#| label: "03b-dplyr-basics-39"
p_line <- df |>
    group_by(start_year, party, sex) |>
    summarize(N = n()) |>
    mutate(freq = N / sum(N)) |>
    ggplot(aes(x = start_year,
               y = freq,
               color = sex)) +
    geom_line(size = 1.1) +
    scale_y_continuous(labels = scales::percent) +
    scale_color_manual(values = sex_colors, labels = c("Women", "Men")) +
    guides(color = guide_legend(reverse = TRUE)) +
    labs(x = "Year", y = "Percent", color = "Group") +
    facet_wrap(~ party)
```

## [Zero Counts]{.fg-orange} in dplyr

```{r}
#| label: "03b-dplyr-basics-40"
#| fig.height: 6
#| fig.width: 9
p_line
```

## Option 1: [factors]{.fg-orange} and [`.drop`]{.fg-red}

Factors are for categorical variables and are stored differently from characters.

This can matter when modeling, and also now.

```{r}
#| label: "03b-dplyr-basics-41"
df_f <- df |> 
  mutate(party_f = factor(party))

df_f
```

## Option 1: [factors]{.fg-orange} and [`.drop`]{.fg-red}

```{r}
#| label: "03b-dplyr-basics-42"
df_f |> 
  group_by(party_f) |> 
  tally()
```

Factors are integer values with named labels, or _levels_:

```{r}
#| label: "03b-dplyr-basics-43"
typeof(df_f$party_f)
levels(df_f$party_f)

```

## Option 1: [factors]{.fg-orange} and [`.drop`]{.fg-red}

By default, unused levels won't display:


```{r}
#| label: "03b-dplyr-basics-44"
df_f <- df |> 
  mutate(party_f = factor(party, 
                          levels = c("Democrat", 
                                     "Republican", 
                                     "Libertarian")))
df_f |> 
  group_by(party_f) |> 
  tally()

levels(df_f$party_f)

```

## Option 1: [factors]{.fg-orange} and [`.drop`]{.fg-red}

By default, unused levels won't display:

```{r}
#| label: "03b-dplyr-basics-45"
df |> 
  mutate(across(where(is.character), as_factor)) |> 
  group_by(start_year, party, sex) |>
  summarize(N = n()) |>
  mutate(freq = N / sum(N))

```

## Option 1: [factors]{.fg-orange} and [`.drop`]{.fg-red}

You can make `dplyr` keep empty factor levels though:

```{r}
#| label: "03b-dplyr-basics-46"
df |> 
  mutate(across(where(is.character), as_factor)) |> 
  group_by(start_year, party, sex, .drop = FALSE) |> #<<
  summarize(N = n()) |>
  mutate(freq = N / sum(N))
  
```

## Option 2: [ungroup()]{.fg-green} and [complete()]{.fg-green}

Maybe you don't want to deal with factors.

```{r}
#| label: "03b-dplyr-basics-47"
df_c <- df |>
    group_by(start_year, party, sex) |>
    summarize(N = n()) |>
    mutate(freq = N / sum(N)) |>
    ungroup() |>#<<
    complete(start_year, party, sex,#<<
             fill = list(N = 0, freq = 0))#<<
```

## Option 2: [ungroup()]{.fg-green} and [complete()]{.fg-green}


```{r}
#| label: "03b-dplyr-basics-48"
df_c
```

## Option 2: [ungroup()]{.fg-green} and [complete()]{.fg-green}

```{r}
#| label: "03b-dplyr-basics-49"
p_out <- df_c |> 
  ggplot(aes(x = start_year,
               y = freq,
               color = sex)) +
    geom_line(size = 1.1) +
    scale_y_continuous(labels = scales::percent) +
    scale_color_manual(values = sex_colors, labels = c("Women", "Men")) +
    guides(color = guide_legend(reverse = TRUE)) +
    labs(x = "Year", y = "Percent", color = "Group") +
    facet_wrap(~ party)
```

## Option 2: [ungroup()]{.fg-green} and [complete()]{.fg-green}

```{r}
#| label: "03b-dplyr-basics-50"
#| fig.height: 6
#| fig.width: 9
p_out
```
